# -*- coding: utf-8 -*-
"""LSTM_Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t46irJi8OThFMiczWe8_Ni94yzumgKbj
"""

import numpy as np
import json
import os
from keras.models import Sequential
from keras.layers import Dense, Input, Dropout, LSTM, Activation, Convolution1D, MaxPooling2D, Flatten
from keras.utils import np_utils
import matplotlib.pyplot as plt
from keras.callbacks import ModelCheckpoint

!mkdir data

!ls ./data

!gsutil -m cp gs://quickdraw_dataset/full/raw/* ./data

!ls ./data

def parse_line(ndjson_line):
  """Parse an ndjson line and return ink (as np array) and classname."""
  sample = json.loads(ndjson_line)
  class_name = sample["word"]
  if not class_name:
    print ("Empty classname")
    return None, None
  inkarray = sample["drawing"]
  stroke_lengths = [len(stroke[0]) for stroke in inkarray]
  total_points = sum(stroke_lengths)
  np_ink = np.zeros((total_points, 3), dtype=np.float32)
  current_t = 0
  if not inkarray:
    print("Empty inkarray")
    return None, None
  for stroke in inkarray:
    if len(stroke[0]) != len(stroke[1]):
      print("Inconsistent number of x and y coordinates.")
      return None, None
    for i in [0, 1]:
      np_ink[current_t:(current_t + len(stroke[0])), i] = stroke[i]
    current_t += len(stroke[0])
    np_ink[current_t - 1, 2] = 1  # stroke_end
  # Preprocessing.
  # 1. Size normalization.
  lower = np.min(np_ink[:, 0:2], axis=0)
  upper = np.max(np_ink[:, 0:2], axis=0)
  scale = upper - lower
  scale[scale == 0] = 1
  np_ink[:, 0:2] = (np_ink[:, 0:2] - lower) / scale
  # 2. Compute deltas.
  np_ink[1:, 0:2] -= np_ink[0:-1, 0:2]
  np_ink = np_ink[1:, :]
  return np_ink, class_name

alarm = './data/alarm clock.ndjson'
book = './data/book.ndjson'
campfire = './data/campfire.ndjson'
cloud = './data/cloud.ndjson'

data_x = np.empty((0,100,3), float)

ctr=0
with open(alarm) as f:
	for line in f:
		a,b = parse_line(line)
		if a.shape[0]>=100:
			ctr+=1
			print ctr
			if ctr>10000:
				break
			a = a[:100,:]
			a[-1,2] = 1.0
			a = a.reshape(1,100,3)
			data_x = np.append(data_x, a, axis=0)

ctr=0
with open(book) as f:
	for line in f:
		a,b = parse_line(line)
		if a.shape[0]>=100:
			ctr+=1
			print ctr
			if ctr>10000:
				break
			a = a[:100,:]
			a[-1,2] = 1.0
			a = a.reshape(1,100,3)
			data_x = np.append(data_x, a, axis=0)

ctr=0
with open(campfire) as f:
	for line in f:
		a,b = parse_line(line)
		if a.shape[0]>=100:
			ctr+=1
			print ctr
			if ctr>10000:
				break
			a = a[:100,:]
			a[-1,2] = 1.0
			a = a.reshape(1,100,3)
			data_x = np.append(data_x, a, axis=0)

print data_x.shape

ctr=0
with open(cloud) as f:
	for line in f:
		a,b = parse_line(line)
		if a.shape[0]>=100:
			ctr+=1
			print ctr
			if ctr>10000:
				break
			a = a[:100,:]
			a[-1,2] = 1.0
			a = a.reshape(1,100,3)
			data_x = np.append(data_x, a, axis=0)

data_y = np.zeros((1,40000))
print data_y.shape
data_y[:,:10000] = 0
data_y[:,10000:20000] = 1
data_y[:,20000:30000] = 2
data_y[:,30000:] = 3

from keras.utils import np_utils
data_y = data_y.reshape(40000,)
data_y = np_utils.to_categorical(data_y)
print data_y.shape

model = Sequential()
model.add(Convolution1D(128,(6),activation='relu', input_shape=(100,3)))
model.add(Convolution1D(64,(3),activation='relu'))
model.add(Convolution1D(1, (1), activation='relu'))
model.add(LSTM(128, return_sequences=True))
# model.add(Dropout(0.5))
model.add(LSTM(128, return_sequences=True))
# model.add(Dropout(0.5))
model.add(LSTM(128, return_sequences=False))
model.add(Dropout(0.5))
model.add(Dense(4))
model.add(Activation('softmax'))

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

checkpoint = [ModelCheckpoint(filepath='/content/drive/My Drive/models.hdf5')]

history = model.fit(data_x, # Features
						data_y, # Target vector
						epochs=30, # Number of epochs
						callbacks=checkpoint, # Checkpoint
						batch_size=100, # Number of observations per batch
						shuffle = True,
						validation_split=0.10)

from google.colab import drive
drive.mount('/content/drive')

model.save('/content/drive/My Drive/Quick_Draw_LSTM.h5')

